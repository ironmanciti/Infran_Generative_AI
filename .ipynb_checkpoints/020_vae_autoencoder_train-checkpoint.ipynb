{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "om2Bs3iExKgt"
   },
   "source": [
    "# 변이형 오토인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d-RSF_EpxKgu"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Conv2D, Flatten, Dense, \\\n\u001b[0;32m      2\u001b[0m                                                 Conv2DTranspose, Reshape, Activation\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, \\\n",
    "                                                Conv2DTranspose, Reshape, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython import display  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fX2vjhh0xKgv"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGrnpEMFxKgv"
   },
   "source": [
    "## 데이터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cnrbv-D2xKgw"
   },
   "outputs": [],
   "source": [
    "def map_image(image, label):\n",
    "    '''주어진 이미지에서 정규화되고 재구성된 텐서를 반환합니다.'''\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    image = image / 255.0\n",
    "    image = tf.reshape(image, shape=(28, 28, 1,))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQy7x2FuxKgw",
    "outputId": "8343076f-d119-422e-f129-d151786a7195"
   },
   "outputs": [],
   "source": [
    "train_dataset = tfds.load('mnist', as_supervised=True, split=\"train\")\n",
    "test_dataset = tfds.load('mnist', as_supervised=True, split=\"test\")\n",
    "train_dataset, len(train_dataset), test_dataset, len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZq4kfG8xKgx",
    "outputId": "5ab4e9ba-5e42-4054-8eaf-6d4b14ecdfcf"
   },
   "outputs": [],
   "source": [
    "train_ds = train_dataset.map(map_image).shuffle(1024).batch(BATCH_SIZE)\n",
    "test_ds = test_dataset.map(map_image).shuffle(1024).batch(BATCH_SIZE)\n",
    "train_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI-Vr-F3xKgx"
   },
   "source": [
    "## 신경망 구조 정의\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1YAZAeMGEJ1KgieYk1ju-S9DoshpMREeC\" width=\"60%\" height=\"60%\"/>\n",
    "\n",
    "### Sampling Class\n",
    "\n",
    "먼저 'Sampling' 클래스를 빌드합니다. 이것은 인코더 출력의 평균 (mu) 및 표준 편차 (sigma)와 함께 가우스 노이즈 입력을 제공하는 맞춤형 Keras 레이어입니다. 실제로 이 레이어의 출력은 다음 방정식으로 제공됩니다.\n",
    "\n",
    "$$z = \\mu + e^{0.5\\sigma} * \\epsilon  $$\n",
    "\n",
    "여기서 $\\mu$ = mean, $\\sigma$ = standard deviation, $\\epsilon$ = random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1XgCYAUxKgx"
   },
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        \"\"\"무작위 샘플을 생성하고 인코더 출력과 결합\n",
    "        Args:\n",
    "          inputs -- output tensor from the encoder (mu, sigma)\n",
    "        Returns:\n",
    "          `inputs` tensors combined with a random sample\n",
    "        \"\"\"\n",
    "        # unpack the output of the encoder\n",
    "        mu, sigma = inputs\n",
    "\n",
    "        # get the size and dimensions of the batch\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "\n",
    "        # generate a random tensor\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "\n",
    "        # reparameterization 적용\n",
    "        return mu + tf.math.exp(0.5 * sigma) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrdpfKseYbQL"
   },
   "source": [
    "### Kullback–Leibler Divergence\n",
    "모델의 생성 능력을 향상 시키려면 잠재 공간에 도입된 랜덤 정규 분포를 고려해야 합니다. 이를 위해 [Kullback–Leibler Divergence](https://arxiv.org/abs/2002.07514)가 계산되어 재구성 손실에 추가됩니다. 공식은 아래 함수에서 정의됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKMxmOHbxKgx"
   },
   "outputs": [],
   "source": [
    "def kl_reconstruction_loss(inputs, outputs, mu, sigma):\n",
    "    \"\"\" Computes the Kullback-Leibler Divergence (KLD)\n",
    "    Args:\n",
    "    inputs -- batch from the dataset\n",
    "    outputs -- output of the Sampling layer\n",
    "    mu -- mean\n",
    "    sigma -- standard deviation\n",
    "\n",
    "    Returns:\n",
    "    KLD loss\n",
    "    \"\"\"\n",
    "    kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
    "    kl_loss = tf.reduce_mean(kl_loss) * -0.5\n",
    "\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUqKgSlOYn_F"
   },
   "source": [
    "### VAE Model\n",
    "이제 전체 VAE 모델을 정의할 수 있습니다. KL reconstruction loss를 추가하기 위해 `model.add_loss()`를 사용합니다. 이 손실을 계산하는 것은 `y_true`와 `y_pred`를 사용하지 않으므로 `model.compile()`에서 사용할 수 없습니다. \n",
    "\n",
    "- add_loss() 메서드 : 손실이 있는 경우, 자동으로 합산되어 주 손실에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAoc6pt1xKgx",
    "outputId": "0e936e0c-b314-4ca4-c4e9-f63c32b90a55"
   },
   "outputs": [],
   "source": [
    " ### THE ENCODER\n",
    "encoder_inputs = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, kernel_size=3, strides=1,\n",
    "                   padding = 'same', activation='leaky_relu')(encoder_inputs)\n",
    "x = Conv2D(64, kernel_size=3, strides=2, \n",
    "                   padding = 'same', activation='leaky_relu')(x)\n",
    "x = Conv2D(64, kernel_size=3, strides=2, \n",
    "                   padding = 'same', activation='leaky_relu')(x)\n",
    "before_flatten = Conv2D(64, kernel_size=3, strides=1,\n",
    "                   padding = 'same', activation='leaky_relu')(x)\n",
    "x = Flatten()(before_flatten)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "\n",
    "mu = Dense(LATENT_DIM, name='mu')(x)\n",
    "sigma = Dense(LATENT_DIM, name='sigma')(x)\n",
    "z = Sampling()((mu, sigma))\n",
    "\n",
    "encoder = Model(encoder_inputs, outputs=[mu, sigma, z])\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iG-o30UxKgy",
    "outputId": "c16ff20f-4e36-4906-d492-b2b61a042451"
   },
   "outputs": [],
   "source": [
    "shape = before_flatten.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWUgLJtkxKgz",
    "outputId": "83a9bc0a-8804-46e8-8dc2-d993f2f5b0c2"
   },
   "outputs": [],
   "source": [
    "### THE DECODER\n",
    "decoder_inputs = Input(shape=(LATENT_DIM,))\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(decoder_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "x = Conv2DTranspose(filters=64, kernel_size=3, strides=1, \n",
    "                        padding = 'same', activation='leaky_relu')(x)\n",
    "x = Conv2DTranspose(filters=64, kernel_size=3, strides=2, \n",
    "                        padding = 'same', activation='leaky_relu')(x)\n",
    "x = Conv2DTranspose(filters=32, kernel_size=3, strides=2, \n",
    "                        padding = 'same', activation='leaky_relu')(x)\n",
    "decoder_output = Conv2DTranspose(filters=1, kernel_size=3, strides=1, \n",
    "                        padding = 'same', activation='sigmoid')(x)\n",
    "decoder = Model(decoder_inputs, decoder_output)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6I-Lur2xKgz"
   },
   "outputs": [],
   "source": [
    "vae_inputs = encoder_inputs\n",
    "mu, sigma, z = encoder(vae_inputs)\n",
    "reconstructed = decoder(z)\n",
    "\n",
    "vae = Model(vae_inputs, reconstructed)\n",
    "# add KL loss\n",
    "loss = kl_reconstruction_loss(vae_inputs, z, mu, sigma)\n",
    "vae.add_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFk9qqqyxKg0"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "bce_loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvMKf_R3xKg0"
   },
   "source": [
    "## 오토인코더 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBNKddyVxZa3"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(decoder, epoch, step, test_input):\n",
    "    \"\"\"Helper function to plot our 16 images\n",
    "    Args:\n",
    "    epoch -- current epoch number during training\n",
    "    step -- current step number during training\n",
    "    test_input -- random tensor with shape (16, LATENT_DIM)\n",
    "    \"\"\"\n",
    "    # generate images from the test input\n",
    "    reconstructed = decoder(test_input)\n",
    "\n",
    "    # plot the results\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(reconstructed.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(reconstructed[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    fig.suptitle(\"epoch: {}, step: {}\".format(epoch, step))\n",
    "    plt.savefig('image_at_epoch_{:04d}_step{:04d}.png'.format(epoch, step))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "I7SlF5GbxKg0",
    "outputId": "4bcf4dac-3c6c-4430-ab7b-457b9c10e6ee"
   },
   "outputs": [],
   "source": [
    "# Training loop. \n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "    for step, (x_batch_train, x_batch_test) in enumerate(zip(train_ds, test_ds)):\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # VAE 모델에 배치 공급\n",
    "            reconstructed = vae(x_batch_train)\n",
    "\n",
    "            # 재구성 손실 계산\n",
    "            flattened_inputs   = tf.reshape(x_batch_train, shape=[-1])\n",
    "            flattened_outputs = tf.reshape(reconstructed, shape=[-1])\n",
    "            loss = bce_loss(flattened_inputs, flattened_outputs) * 784\n",
    "\n",
    "            # add KLD regularization loss\n",
    "            loss += sum(vae.losses)  \n",
    "\n",
    "        # get the gradients and update the weights\n",
    "        grads = tape.gradient(loss, vae.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "\n",
    "        # compute the loss metric\n",
    "        loss_metric(loss)\n",
    "\n",
    "        # display outputs every 100 steps\n",
    "        if step % 100 == 0:\n",
    "            display.clear_output(wait=False)    \n",
    "            _, _, z = encoder(x_batch_test[:16])\n",
    "            generate_and_save_images(decoder, epoch, step, z)\n",
    "            print('Epoch: %s step: %s mean loss = %s' % (epoch, step, loss_metric.result().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "XHXyRpg9ASS5",
    "outputId": "16248720-35d6-412a-a038-d3a6846eeb9f"
   },
   "outputs": [],
   "source": [
    "x_batch_test = next(iter(test_ds))\n",
    "print(x_batch_test.shape)\n",
    "\n",
    "_, _, z = encoder(x_batch_test[:16])\n",
    "generate_and_save_images(decoder, epoch, step, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFOAwbrf5LAb"
   },
   "source": [
    "## 원본 그림 재구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHuG-kdsNCaz",
    "outputId": "22aa7bdc-6a52-45eb-bce3-ecb3ffaff3b3"
   },
   "outputs": [],
   "source": [
    "n_to_show = 10\n",
    "example_images = x_batch_test[:n_to_show]\n",
    "example_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CA9yqpb7DAbL"
   },
   "outputs": [],
   "source": [
    "mu, sigma, z = encoder(example_images)\n",
    "reconst_images  = decoder(mu, sigma, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "5A4fzcv9xKg0",
    "outputId": "7f712859-eb80-49a5-d47e-096a59ba90ae"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(n_to_show):\n",
    "    img = example_images[i].numpy().squeeze()\n",
    "    sub = fig.add_subplot(2, n_to_show, i+1)\n",
    "    sub.axis('off')\n",
    "    sub.text(0.5, -0.35, str(np.round(z[i],1)), fontsize=10, ha='center', transform=sub.transAxes)      \n",
    "    sub.imshow(img, cmap='gray_r')\n",
    "\n",
    "for i in range(n_to_show):\n",
    "    img = reconst_images[i].numpy().reshape(28, 28)\n",
    "    sub = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
    "    sub.axis('off')\n",
    "    sub.imshow(img, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hd8LFXEZXA2Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "03_01_vae_autoencoder_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
